{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "cXQi9QHozjMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "RUN_TRAINING_CELLS = IN_COLAB\n",
        "\n",
        "EXPERIMENT_NAME = 'MedicalSummary/'\n",
        "DRIVE_FOLDER_LOCATION = '/content/drive/My Drive/VivekaHackathon2024/' + EXPERIMENT_NAME"
      ],
      "metadata": {
        "id": "XBJyEz52zkZ6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting google drive\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV-Cv_EQzoSL",
        "outputId": "8bdaabab-37fe-4c03-b906-1099f8d347dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup\n",
        "## Setting up Google Drive as working directory and installing Packages"
      ],
      "metadata": {
        "id": "ulXEVKjV0EQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using my own Google Drive during the experiment to save all checkpoints and training logs.\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Adapted from:  https://robertbrucecarter.com/writing/2020/06/setting-your-working-directory-to-google-drive-in-a-colab-notebook/\n",
        "    import os\n",
        "\n",
        "    def create_and_set_working_directory(path: str):\n",
        "        # check if your project folder exists. if not, it will be created.\n",
        "        if os.path.isdir(path) == False:\n",
        "            os.makedirs(path)\n",
        "            print(path + ' did not exist but was created.')\n",
        "\n",
        "        # change the OS to use your project folder as the working directory\n",
        "        os.chdir(path)\n",
        "\n",
        "        print('Working directory changed to: \\n' + path)\n",
        "\n",
        "    create_and_set_working_directory(DRIVE_FOLDER_LOCATION)\n",
        "    !pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ACJsoWLz45y",
        "outputId": "7fdb373d-3add-4893-9bac-a43e59b05976"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working directory changed to: \n",
            "/content/drive/My Drive/VivekaHackathon2024/MedicalSummary/\n",
            "/content/drive/My Drive/VivekaHackathon2024/MedicalSummary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsing the XML files to create suitable dataset"
      ],
      "metadata": {
        "id": "1l4_AmepC9W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# This is an example function to extract relevant information from the PubMed Subset XML\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Extracting relevant information based on the provided XML structure\n",
        "    title_element = root.find('.//article-title')\n",
        "    abstract_element = root.find('.//abstract')\n",
        "\n",
        "    title = title_element.text if title_element is not None else None\n",
        "    # Join all paragraphs in the abstract\n",
        "    abstract = ' '.join([p.text for p in abstract_element.findall('p')]) if abstract_element is not None else None\n",
        "\n",
        "    # Return as dictionary\n",
        "    return {\n",
        "        'title': title,\n",
        "        'abstract': abstract\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/drive/MyDrive/VivekaHackathon2024/PMC000xxxxxx/PMC176545.xml'\n",
        "data = parse_xml(file_path)\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "Wu49xH960RGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26770751-8b98-4700-e563-737d45a6dfc5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'The Transcriptome of the Intraerythrocytic Developmental Cycle of ', 'abstract': '\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Script to parse all the XML files from the PubMed Subset\n"
      ],
      "metadata": {
        "id": "hmZLyMQwDU5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "def parse_xml(file_path):\n",
        "    try:\n",
        "        tree = ET.parse(file_path)\n",
        "        root = tree.getroot()\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"Error parsing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Extracting relevant information based on the provided XML structure\n",
        "    title_element = root.find('.//article-title')\n",
        "    abstract_element = root.find('.//abstract')\n",
        "    body_elements = root.findall('.//body//p')\n",
        "\n",
        "    title = title_element.text if title_element is not None else None\n",
        "\n",
        "    if abstract_element is not None:\n",
        "        abstract_paragraphs = [p.text for p in abstract_element.findall('p') if p.text is not None]\n",
        "        abstract = ' '.join(abstract_paragraphs)\n",
        "    else:\n",
        "        abstract = None\n",
        "\n",
        "    if body_elements:\n",
        "        body_paragraphs = [p.text for p in body_elements if p.text is not None]\n",
        "        body = ' '.join(body_paragraphs)\n",
        "    else:\n",
        "        body = None\n",
        "\n",
        "    # Check if title and abstract are found\n",
        "    if not title or not abstract:\n",
        "        print(f\"Missing title or abstract in file: {file_path}\")\n",
        "\n",
        "    # Return as dictionary\n",
        "    return {\n",
        "        'title': title,\n",
        "        'abstract': abstract,\n",
        "        'body': body\n",
        "    }\n",
        "\n",
        "def parse_all_xmls(directory):\n",
        "    all_data = []\n",
        "    for file_path in glob.glob(os.path.join(directory, '*.xml')):\n",
        "        data = parse_xml(file_path)\n",
        "        if data:\n",
        "            all_data.append(data)\n",
        "    return all_data\n",
        "\n",
        "# Directory containing XML files\n",
        "directory = '/content/drive/MyDrive/VivekaHackathon2024/PMC000xxxxxx'\n",
        "all_data = parse_all_xmls(directory)\n",
        "\n",
        "# Convert to DataFrame and save\n",
        "df = pd.DataFrame(all_data)\n",
        "df.to_csv('/content/drive/MyDrive/VivekaHackathon2024/medical_summaries.csv', index=False)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "ZsiG6Bvz8wr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for replacing complex terms into simple terms in the summaries by using Consumer Health Vocabulary (CHV) dataset.\n"
      ],
      "metadata": {
        "id": "4qdUPK4UDkNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CHV file\n",
        "chv_path = '/content/drive/MyDrive/VivekaHackathon2024/CHV-amia14-data.tsv'\n",
        "chv_df = pd.read_csv(chv_path, sep='\\t', header=0)\n",
        "\n",
        "# Create a dictionary for quick lookup\n",
        "chv_dict = pd.Series(chv_df['CONSUMER'].values, index=chv_df['PROFESSIONAL']).to_dict()\n",
        "\n",
        "# Display some entries to ensure it is loaded correctly\n",
        "print(list(chv_dict.items())[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMCLydgzByal",
        "outputId": "25d1a7f6-bf93-4abf-81fd-2723ed54d331"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('nausea', 'Morning sickness'), ('eidetic memory', 'photographic memory'), ('aliment', 'Nutrition'), ('Lynch syndrome', 'hereditary nonpolyposis colorectal cancer (HNPCC)'), ('xerophthalmia', 'Keratoconjunctivitis sicca (KCS)'), ('Guinea pepper', 'spice'), ('vision training', 'Vision therapy'), ('primary ovarian insufficiency', 'Premature Ovarian Failure'), ('alligator pepper', 'spice'), ('GM2 gangliosidosis', 'Tayâ€“Sachs disease')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replacing Professional Terms with Consumer Terms in Abstract/Summaries"
      ],
      "metadata": {
        "id": "b4ZpHqEnGZi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load the CHV file\n",
        "chv_path = '/content/drive/MyDrive/VivekaHackathon2024/CHV-amia14-data.tsv'\n",
        "chv_df = pd.read_csv(chv_path, sep='\\t', header=0)\n",
        "\n",
        "# Create a dictionary for quick lookup\n",
        "chv_dict = pd.Series(chv_df['CONSUMER'].values, index=chv_df['PROFESSIONAL']).to_dict()\n",
        "\n",
        "def simplify_text(text, chv_dict):\n",
        "    # Lowercase the text\n",
        "    # text = text.lower()\n",
        "    # Tokenize the text into words\n",
        "    words = text.split()\n",
        "    # Replace each word if it exists in the CHV dictionary\n",
        "    simplified_words = [chv_dict.get(word.lower(), word) for word in words]\n",
        "    # Join the words back into a single string\n",
        "    simplified_text = ' '.join(simplified_words)\n",
        "    return simplified_text\n",
        "\n",
        "# Load the DataFrame with titles and abstracts\n",
        "df = pd.read_csv('/content/drive/MyDrive/VivekaHackathon2024/medical_summaries.csv')\n",
        "\n",
        "# Apply the simplification to each abstract\n",
        "df['simplified_abstract'] = df['abstract'].apply(lambda x: simplify_text(str(x), chv_dict) if pd.notnull(x) else x)\n",
        "\n",
        "# Count the number of abstracts that were changed\n",
        "num_changed = df[df['abstract'] != df['simplified_abstract']].shape[0]\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "df.to_csv('/content/drive/MyDrive/VivekaHackathon2024/medical_summaries_simplified.csv', index=False)\n",
        "\n",
        "print(f\"Number of abstracts changed: {num_changed}\")\n",
        "print(df[['abstract', 'simplified_abstract']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJWa9FySD7rP",
        "outputId": "554e90be-9a37-4330-cddf-1f68cb376ca3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of abstracts changed: 2454\n",
            "  abstract simplified_abstract\n",
            "0      NaN                 NaN\n",
            "1      NaN                 NaN\n",
            "2      NaN                 NaN\n",
            "3      NaN                 NaN\n",
            "4      NaN                 NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame containing 'abstract' and 'simplified_abstract' columns\n",
        "# Load or create df as needed\n",
        "\n",
        "# Drop rows where both 'abstract' and 'simplified_abstract' are NaN\n",
        "df_clean = df.dropna(subset=['abstract', 'simplified_abstract'], how='all')\n",
        "\n",
        "# Reset the index of the cleaned DataFrame\n",
        "df_clean.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Save the cleaned DataFrame to a new CSV file\n",
        "df_clean.to_csv('/content/drive/MyDrive/VivekaHackathon2024/medical_summaries_clean.csv', index=False)\n",
        "\n",
        "# Print the cleaned DataFrame\n",
        "print(df_clean[['abstract', 'simplified_abstract']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcxD0NFTGfmC",
        "outputId": "810b3d7d-efb0-4ba0-ce31-1ad8938211ff"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            abstract  \\\n",
            "0  Asthma is a common disease and appears to be i...   \n",
            "1  While many lessons have been learned from the ...   \n",
            "2  The use of spatially referenced data in cancer...   \n",
            "3  There has long been a recognition that place m...   \n",
            "4  EB-GIS4HEALTH UK aims at building a UK-oriente...   \n",
            "\n",
            "                                 simplified_abstract  \n",
            "0  Asthma is a common disease and appears to be i...  \n",
            "1  While many lessons have been learned from the ...  \n",
            "2  The use of spatially referenced data in cancer...  \n",
            "3  There has long been a recognition that place m...  \n",
            "4  EB-GIS4HEALTH UK aims at building a UK-oriente...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df_clean is your cleaned DataFrame\n",
        "df_clean = pd.read_csv('/content/drive/MyDrive/VivekaHackathon2024/medical_summaries_clean.csv')  # Load the cleaned DataFrame\n",
        "\n",
        "# Count the number of rows in the cleaned DataFrame\n",
        "num_rows = df_clean.shape[0]\n",
        "\n",
        "print(f\"Number of rows with valid content: {num_rows}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1ehuq8LIJQf",
        "outputId": "f2f3b306-82c5-44c2-cf1b-4ee58b048776"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with valid content: 757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation for Training"
      ],
      "metadata": {
        "id": "KaWTCIBmKEvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the DataFrame (if not already loaded)\n",
        "df = pd.read_csv('/content/drive/MyDrive/VivekaHackathon2024/medical_summaries_clean.csv')\n",
        "\n",
        "# Define the input and target columns for T5 fine-tuning\n",
        "df['input_text'] = 'summarize: ' + df['title'].fillna('') + ' ' + df['abstract'].fillna('') + ' ' + df['body'].fillna('')\n",
        "df['target_text'] = df['abstract'].fillna('')  # Using abstract as the summary for fine-tuning\n",
        "\n",
        "# Save the prepared dataset to a CSV file\n",
        "df[['input_text', 'target_text']].to_csv('/content/drive/MyDrive/VivekaHackathon2024/t5_training_data.csv', index=False)\n",
        "\n",
        "print(df[['input_text', 'target_text']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq8Z87GoIbDj",
        "outputId": "100d025c-50ec-488e-a65b-7afb615e0759"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          input_text  \\\n",
            "0  summarize: Road-traffic pollution and asthma â€“...   \n",
            "1  summarize: Current practices in the spatial an...   \n",
            "2  summarize: Current practices in spatial analys...   \n",
            "3  summarize: Current practices in cancer spatial...   \n",
            "4  summarize: Research protocol: EB-GIS4HEALTH UK...   \n",
            "\n",
            "                                         target_text  \n",
            "0  Asthma is a common disease and appears to be i...  \n",
            "1  While many lessons have been learned from the ...  \n",
            "2  The use of spatially referenced data in cancer...  \n",
            "3  There has long been a recognition that place m...  \n",
            "4  EB-GIS4HEALTH UK aims at building a UK-oriente...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hZsKZlqdKwW3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}